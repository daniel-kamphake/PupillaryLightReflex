{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b37b5b",
   "metadata": {},
   "source": [
    "# Basic pre-assembled models\n",
    "In this section we train the basic models which Ultralytics provides per default. \n",
    "All of those models come with COCO weights and thus benefit from Transfer Learning and have a good baseline performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1959d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJECT_NAME = 'Unity_Eyes'\n",
    "\n",
    "def get_basic_settings(name, epochs, project_name=PROJECT_NAME):\n",
    "    train = f'{CURRENT_DIR}/yolov5/yolov5/train.py'\n",
    "    data = f'--data {CURRENT_DIR}/yolov5/yolov5/unity_eyes.yaml'\n",
    "    output = f'--project {CURRENT_DIR}/models/{PROJECT_NAME} --name {name}'\n",
    "    \n",
    "    settings = f'--imgsz 320 --epochs {epochs}'\n",
    "    \n",
    "    return train, data, output, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d805b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_basic_xtra_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Xtra', epochs)    \n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 16 --weights yolov5x.pt\n",
    "        \n",
    "        \n",
    "def train_basic_large_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Large', epochs)    \n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 16 --weights yolov5l.pt\n",
    "        \n",
    "        \n",
    "def train_basic_medium_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Medium', epochs)    \n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 16 --weights yolov5m.pt\n",
    "        \n",
    "        \n",
    "def train_basic_small_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Small', epochs)    \n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 16 --weights yolov5s.pt\n",
    "        \n",
    "        \n",
    "def train_basic_nano_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Nano', epochs)    \n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 16 --weights yolov5n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8234d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_basic_nano_model(10)\n",
    "    train_basic_small_model(10)\n",
    "    train_basic_medium_model(10)\n",
    "    train_basic_large_model(10)\n",
    "    train_basic_xtra_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac50d2",
   "metadata": {},
   "source": [
    "## Analyzing Batch Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a19efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Batch_Sizes'\n",
    "\n",
    "def train_nano_model_batch(repitions, batch_size=16, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings(f'Nano_Batch_{batch_size}', epochs, \n",
    "                                                       project_name=f'{PROJECT_NAME}_Batch')    \n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch {batch_size} --weights yolov5n.pt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33caba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_nano_model_batch(4, batch_size=256)\n",
    "    train_nano_model_batch(4, batch_size=128)\n",
    "    train_nano_model_batch(4, batch_size=64)\n",
    "    train_nano_model_batch(4, batch_size=32)\n",
    "    train_nano_model_batch(4, batch_size=16)\n",
    "    train_nano_model_batch(4, batch_size=8)\n",
    "    \n",
    "    train_nano_model_batch(2, batch_size=256)\n",
    "    train_nano_model_batch(2, batch_size=128)\n",
    "    train_nano_model_batch(2, batch_size=64)\n",
    "    train_nano_model_batch(2, batch_size=32)\n",
    "    train_nano_model_batch(2, batch_size=16)\n",
    "    train_nano_model_batch(2, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594855a",
   "metadata": {},
   "source": [
    "|Batch|Memory|Time Epoch|mAP.95|\n",
    "|-----|----- |----------|------|\n",
    "|256  |6.04G |14.57min  |96.87%|\n",
    "|128  |4.62G |17.54min  |97.11%|\n",
    "|64   |2.25G |19.03min  |97.26%|\n",
    "|32   |1.16G |19.52min  |97.37%|\n",
    "|16   |0.60G |44.09min  |97.09%|\n",
    "|8    |0.28G |64.63min  |97.11%|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e9b43",
   "metadata": {},
   "source": [
    "# First WandB Sweep - Random Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15f614f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "    \"program\" : f'{CURRENT_DIR}/yolov5/yolov5/train_wrapper.py',\n",
    "    \"project\" : f'{CURRENT_DIR}/models/Unity_Nano_Sweep',\n",
    "    \"name\" : \"Nano_Sweep\",\n",
    "    \"method\" : \"random\",\n",
    "    \"metric\": {\n",
    "      \"goal\": \"maximize\",\n",
    "      \"name\": \"metrics/mAP_0.5:0.95\"},\n",
    "    \"parameters\" : {   \n",
    "      \"batch_size\": { \"max\": 32, \"min\": 16, \"distribution\": \"int_uniform\"},\n",
    "      \"weight_decay\": { \"max\": 0.001, \"min\": 0.00025, \"distribution\": \"uniform\"},\n",
    "      \"translate\": { \"max\": 0.2, \"min\": 0.05, \"distribution\": \"uniform\"},\n",
    "      \"momentum\": { \"max\": 1.0, \"min\": 0.4685, \"distribution\": \"uniform\"},\n",
    "      \"fliplr\": { \"max\": 1, \"min\": 0.25, \"distribution\": \"uniform\"},\n",
    "      \"scale\": { \"max\": 1, \"min\": 0.25, \"distribution\": \"uniform\"},\n",
    "      \"iou_t\": { \"max\": 0.4, \"min\": 0.1, \"distribution\": \"uniform\"},\n",
    "      \"hsv_v\": { \"max\": 0.8, \"min\": 0.2, \"distribution\": \"uniform\"},\n",
    "      \"hsv_s\": { \"max\": 1.4, \"min\": 0.35, \"distribution\": \"uniform\"},\n",
    "      \"hsv_h\": { \"max\": 0.03, \"min\": 0.0075, \"distribution\": \"uniform\"},\n",
    "      \"lrf\": { \"max\": 0.2, \"min\": 0.05, \"distribution\": \"uniform\"},\n",
    "      \"lr0\": { \"max\": 0.02, \"min\": 0.005, \"distribution\": \"uniform\"},\n",
    "      \"cls\": { \"max\": 1, \"min\": 0.25, \"distribution\": \"uniform\"},\n",
    "      \"box\": { \"max\": 0.1, \"min\": 0.025, \"distribution\": \"uniform\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "if False:\n",
    "    sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03aa4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    !wandb agent daniel-kamphake/uncategorized/w5nirba8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc85df",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "* Batch # 16-32\n",
    "* translate # 0.05 - 0.2\n",
    "* fliplr # 0.25-1\n",
    "* scale \n",
    "* momentum # 0.4685 - 1.0\n",
    "* hsv_h # 0.0075 - 0.03\n",
    "* lr0 # 0.005 - 0.02 \n",
    "* cls # 0.25-1\n",
    "* box # 0.025 - 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d11216",
   "metadata": {},
   "source": [
    "# Second WandB Sweep - Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2d8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config_new = {\n",
    "    \"program\" : f'{CURRENT_DIR}/yolov5/yolov5/train_wrapper.py',\n",
    "    \"project\" : f'{CURRENT_DIR}/models/Unity_Nano_Sweep_2',\n",
    "    \"name\" : \"Nano_Sweep_2\",\n",
    "    \"method\" : \"bayes\",\n",
    "    \"metric\": {\n",
    "      \"goal\": \"maximize\",\n",
    "      \"name\": \"metrics/mAP_0.5:0.95\"},\n",
    "    \"parameters\" : {   \n",
    "      \"batch_size\": { \"max\": 40, \"min\": 24, \"distribution\": \"int_uniform\"},\n",
    "      \"weight_decay\": { \"max\": 0.001, \"min\": 0.00025, \"distribution\": \"uniform\"},\n",
    "      \"translate\": { \"max\": 0.1, \"min\": 0.0, \"distribution\": \"uniform\"},\n",
    "      \"fliplr\": { \"max\": 0.6, \"min\": 0.4, \"distribution\": \"uniform\"},\n",
    "      \"scale\": { \"max\": 0.6, \"min\": 0.4, \"distribution\": \"uniform\"},\n",
    "      \"momentum\": { \"max\": 0.9, \"min\": 0.7, \"distribution\": \"uniform\"},\n",
    "      \"hsv_v\": { \"max\": 0.8, \"min\": 0.2, \"distribution\": \"uniform\"},\n",
    "      \"hsv_s\": { \"max\": 1.4,  \"min\": 0.35, \"distribution\": \"uniform\"},\n",
    "      \"hsv_h\": { \"max\": 0.025, \"min\": 0.01, \"distribution\": \"uniform\"},\n",
    "      \"lr0\": { \"max\": 0.02, \"min\": 0.0125, \"distribution\": \"uniform\"},\n",
    "      \"cls\": { \"max\": 0.5, \"min\": 0.2, \"distribution\": \"uniform\"},\n",
    "      \"box\": { \"max\": 0.125, \"min\": 0.05, \"distribution\": \"uniform\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "if False:\n",
    "    sweep_id = wandb.sweep(sweep_config_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d9d32b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    !wandb agent daniel-kamphake/uncategorized/12chmrr7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93cc9c",
   "metadata": {},
   "source": [
    "# Train with specific configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8470f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /home/daniel/Seafile/Masterarbeit/pupil-detection/yolov5/yolov5/train_wrapper.py --data /home/daniel/Seafile/Masterarbeit/pupil-detection/yolov5/yolov5/unity_eyes.yaml --project /home/daniel/Seafile/Masterarbeit/pupil-detection/models/Unity_Eyes --name Nano_opt --imgsz 320 --epochs 20 --weights yolov5n.pt --batch_size=40 --box=0.123 --cls=0.2 --hsv_h=0.014 --hsv_v=0.37 --hsv_s=1.2 --shear=0.0 --degrees=0.0 --fliplr=0.43 --scale=0.54 --translate=0.08 --lrf=0.02 --lr0=0.0165 --momentum=0.89  --weight_decay=0.0009 --iou_t=0.017\n"
     ]
    }
   ],
   "source": [
    "Path = f'/home/daniel/Seafile/Masterarbeit/pupil-detection/yolov5/yolov5/train_wrapper.py'\n",
    "batch = f'--batch_size=40'\n",
    "loss = f'--box=0.123 --cls=0.2'\n",
    "image = f'--hsv_h=0.014 --hsv_v=0.37 --hsv_s=1.2 --shear=0.0 --degrees=0.0'\n",
    "augments = f'--fliplr=0.43 --scale=0.54 --translate=0.08'\n",
    "learn_rate = f'--lrf=0.02 --lr0=0.0165 --momentum=0.89  --weight_decay=0.0009 --iou_t=0.017' \n",
    "data = f'--data {CURRENT_DIR}/yolov5/yolov5/unity_eyes.yaml'\n",
    "output = f'--project {CURRENT_DIR}/models/{PROJECT_NAME} --name Nano_opt'\n",
    "settings = f'--imgsz 320 --epochs 20 --weights yolov5n.pt'\n",
    "\n",
    "command = f'python {Path} {data} {output} {settings} {batch} {loss} {image} {augments} {learn_rate}'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551e955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaniel-kamphake\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mtrain_wrapper: \u001b[0mweights=yolov5n.pt, cfg=, data=/home/daniel/Seafile/Masterarbeit/pupil-detection/yolov5/yolov5/unity_eyes.yaml, hyp=/home/daniel/Seafile/Masterarbeit/pupil-detection/yolov5/yolov5/data/hyps/sweep_hyper.yaml, epochs=20, batch_size=40, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=/home/daniel/Seafile/Masterarbeit/pupil-detection/models/Unity_Eyes, name=Nano_opt, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, lr0=0.0165, lrf=0.02, cls=0.2, box=0.123, momentum=0.89, weight_decay=0.0009, iou_t=0.017, hsv_v=0.37, hsv_s=1.2, hsv_h=0.014, fliplr=0.43, scale=0.54, degrees=0.0, shear=0.0, translate=0.08, mosaic=0.9\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 🚀 51a0690 torch 1.9.0+cu111 CUDA:0 (GeForce RTX 2070, 7974MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0165, lrf=0.02, momentum=0.89, weight_decay=0.0009, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.123, cls=0.2, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.017, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.014, hsv_s=1.2, hsv_v=0.37, degrees=0.0, translate=0.08, scale=0.54, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.43, mosaic=0.9, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /home/daniel/Seafile/Masterarbeit/pupil-detection/models/Unity_Eyes', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mNano_opt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/daniel-kamphake/Unity_Eyes\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/daniel-kamphake/Unity_Eyes/runs/18e79sev\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/daniel/Seafile/Masterarbeit/pupil-detection/wandb/run-20211120_030130-18e79sev\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
      "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
      "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
      "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
      "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
      "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
      " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 24      [17, 20, 23]  1      9471  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
      "Model Summary: 270 layers, 1766623 parameters, 1766623 gradients, 4.2 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5n.pt\n",
      "Scaled weight_decay = 0.001125\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../pupil-detection/yolov5/unity_eyes/labels/train.cache' images\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '../pupil-detection/yolov5/unity_eyes/labels/val.cache' images and\u001b[0m\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Plotting labels to /home/daniel/Seafile/Masterarbeit/pupil-detection/models/Unity_Eyes/Nano_opt2/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.92 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Image sizes 320 train, 320 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/daniel/Seafile/Masterarbeit/pupil-detection/models/Unity_Eyes/Nano_opt2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/19     1.13G    0.1019   0.01758  0.003026        88       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2000       2000      0.998      0.998      0.995      0.658\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      1/19     1.41G   0.06028   0.00966  0.001231        92       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2000       2000          1          1      0.995      0.875\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      2/19     1.41G    0.0565  0.008397 0.0009563        88       320: 100%|███\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all       2000       2000      0.999          1      0.995      0.838\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      3/19     1.41G   0.04747  0.007559 0.0008537        88       320: 100%|███\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class     Images     Labels          P          R     mAP@.5 mAP@"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    for _ in range(20):\n",
    "        !{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf69ed",
   "metadata": {},
   "source": [
    "# Weightless Training with Nano and Micro\n",
    "In this section we reduce the size of the Nano model by decreasing the scaling factors in the `.yaml` file, which describes the architecture of each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e31293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Weightless'\n",
    "\n",
    "def get_weightless_settings(name, epochs, project_name=PROJECT_NAME):\n",
    "    train = f'{CURRENT_DIR}/yolov5/yolov5/train.py'\n",
    "    data = f'--data {CURRENT_DIR}/yolov5/yolov5/unity_eyes.yaml'\n",
    "    output = f'--project {CURRENT_DIR}/models/{PROJECT_NAME} --name {name}'\n",
    "    \n",
    "    settings = f'--imgsz 320 --epochs {epochs}'\n",
    "    \n",
    "    return train, data, output, settings\n",
    "\n",
    "\n",
    "def train_weightless_nano_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Nano', epochs)   \n",
    "    cfg = f'--cfg {CURRENT_DIR}/yolov5/yolov5/models/yolov5n.yaml'\n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 40 {cfg}\n",
    "                \n",
    "\n",
    "def train_weightless_nano_shallow_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Shallow', epochs)   \n",
    "    cfg = f'--cfg {CURRENT_DIR}/yolov5/yolov5/models/yolov5n_shallow.yaml'\n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 40 {cfg}\n",
    "                \n",
    "\n",
    "def train_weightless_nano_thin_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Thin', epochs)   \n",
    "    cfg = f'--cfg {CURRENT_DIR}/yolov5/yolov5/models/yolov5n_thin.yaml'\n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 40 {cfg}\n",
    "                            \n",
    "\n",
    "def train_weightless_micro_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Micro', epochs)   \n",
    "    cfg = f'--cfg {CURRENT_DIR}/yolov5/yolov5/models/yolov5micro.yaml'\n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 40 {cfg}\n",
    "        \n",
    "\n",
    "def train_weightless_super_micro_model(repitions, epochs=20): \n",
    "    train, data, output, settings = get_basic_settings('Super Micro', epochs)   \n",
    "    cfg = f'--cfg {CURRENT_DIR}/yolov5/yolov5/models/yolov5micro_super.yaml'\n",
    "    for i in range(repitions):\n",
    "        !python {train} {data} {settings} {output} --batch 40 {cfg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ee6c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    train_weightless_nano_model(10)\n",
    "    train_weightless_nano_shallow_model(10)\n",
    "    train_weightless_nano_thin_model(10)\n",
    "    train_weightless_micro_model(10)    \n",
    "    train_weightless_super_micro_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78715c",
   "metadata": {},
   "source": [
    "## Nano\n",
    "Model Summary: 270 layers, 1766623 parameters, 1766623 gradients, 4.2 GFLOPs\n",
    "\n",
    "20 epochs completed in 0.276 hours.\n",
    "\n",
    "## Shallow\n",
    "Model Summary: 243 layers, 1673823 parameters, 1673823 gradients, 3.8 GFLOPs\n",
    "\n",
    "20 epochs completed in 0.257 hours.\n",
    "\n",
    "## Thin\n",
    "Model Summary: 270 layers, 329207 parameters, 329207 gradients, 1.0 GFLOPs\n",
    "\n",
    "20 epochs completed in 0.240 hours.\n",
    "\n",
    "## Micro\n",
    "Model Summary: 243 layers, 310679 parameters, 310679 gradients, 0.9 GFLOPs\n",
    "\n",
    "20 epochs completed in 0.241 hours.\n",
    "\n",
    "## Super Micro\n",
    "Model Summary: 192 layers, 94651 parameters, 94651 gradients, 0.4 GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475fd46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
