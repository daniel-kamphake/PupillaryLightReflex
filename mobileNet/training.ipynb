{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source\n",
    "This Notebook was mostly taken from https://github.com/nicknochnack/TFODCourse. (1.08.2021)\n",
    "\n",
    "It was adapted to train multiple models and customized to use the prepared datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883f895243e14a3a887bfbbdfa647d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Train for:', index=2, options=('eye', 'iris', 'pupil', 'unity_eyes'), value='pupil')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a390cef0eb41279aa5030786a94e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Weights:', options=('coco',), value='coco')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "\n",
    "objectChooser = widgets.Dropdown(\n",
    "    options=['eye', 'iris', 'pupil', 'unity_eyes'],\n",
    "    value='pupil',\n",
    "    description='Train for:',\n",
    "    disabled=False,\n",
    ")\n",
    "modelChooser = widgets.Dropdown(\n",
    "    options=['coco'],\n",
    "    value='coco',\n",
    "    description='Weights:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(objectChooser)\n",
    "display(modelChooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'ssd_mobnet_' + modelChooser.value + \"_\"+ objectChooser.value \n",
    "LABEL_MAP_NAME = 'eyes_label_map.pbtxt'\n",
    "LABEL_TXT_NAME = 'labels.txt'\n",
    "META_JSON_DEFAULT = 'meta.json'\n",
    "META_JSON_CUSTOM = 'meta' + modelChooser.value + '.json'\n",
    "\n",
    "if modelChooser.value == 'coco':\n",
    "    PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "    PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "    \n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join(objectChooser.value),\n",
    "    'MODEL_PATH': os.path.join(objectChooser.value, 'models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join(objectChooser.value, 'models', CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join(objectChooser.value, 'models', CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFLITE_PATH':os.path.join(objectChooser.value, 'models', CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc'),\n",
    " }\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join(objectChooser.value, 'models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME),\n",
    "    'LABELTXT': os.path.join(paths['ANNOTATION_PATH'], LABEL_TXT_NAME),\n",
    "    'META_DEFAULT': os.path.join('Tensorflow', META_JSON_DEFAULT),   \n",
    "    'META_CUSTOM': os.path.join(paths['ANNOTATION_PATH'], META_JSON_CUSTOM),    \n",
    "}\n",
    "    \n",
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iA1DIq5OpfDE"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839e731b24c34de2a924f8a8f89d40d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='lib issues')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9190fd317d1406daffaf3e27ee89e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Verification')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "issues = widgets.ToggleButton(value=False, description='lib issues')\n",
    "verify = widgets.ToggleButton(value=False, description='Verification')\n",
    "display(issues)\n",
    "display(verify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-22 10:39:30--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 2a00:1450:4001:829::2010, 142.250.186.144\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|2a00:1450:4001:829::2010|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20515344 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19,56M  22,4MB/s    in 0,9s    \n",
      "\n",
      "2021-11-22 10:39:31 (22,4 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if issues.value:# Install Tensorflow Object Detection \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "    !pip install tensorflow --upgrade\n",
    "    !pip uninstall protobuf matplotlib -y\n",
    "    !pip install protobuf matplotlib==3.2\n",
    "    \n",
    "if verify.value:\n",
    "    VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "    # Verify Installation\n",
    "    !python {VERIFICATION_SCRIPT}\n",
    "    \n",
    "import object_detection\n",
    "\n",
    "!wget {PRETRAINED_MODEL_URL}\n",
    "!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name': objectChooser.value, 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "        \n",
    "with open(files['LABELTXT'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('{}\\n'.format(label['name']))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# 3. Update Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "#!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd3c271a7664650a531fe6ee7d22ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2000, description='Trainsteps:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "\n",
    "steps = widgets.IntText(\n",
    "    value=2000,\n",
    "    description='Trainsteps:',\n",
    "    disabled=False\n",
    ")\n",
    "display(steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=pupil/models/ssd_mobnet_coco_pupil --pipeline_config_path=pupil/models/ssd_mobnet_coco_pupil/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'],steps.value)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 10:39:48.678363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 10:39:48.680722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2021-11-22 10:39:48.681093: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-22 10:39:48.681425: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W1122 10:39:48.683098 139998094067520 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I1122 10:39:48.684829 139998094067520 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I1122 10:39:48.688928 139998094067520 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1122 10:39:48.689018 139998094067520 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1122 10:39:48.704227 139998094067520 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['pupil/train.record']\n",
      "I1122 10:39:48.705682 139998094067520 dataset_builder.py:163] Reading unweighted datasets: ['pupil/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['pupil/train.record']\n",
      "I1122 10:39:48.705753 139998094067520 dataset_builder.py:80] Reading record datasets for input file: ['pupil/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1122 10:39:48.705788 139998094067520 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1122 10:39:48.705819 139998094067520 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W1122 10:39:48.710325 139998094067520 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1122 10:39:48.726872 139998094067520 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1122 10:39:53.761663 139998094067520 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1122 10:39:55.883976 139998094067520 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1122 10:39:57.027101 139998094067520 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-11-22 10:39:58.565868: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-22 10:39:58.772735: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "/home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W1122 10:40:11.231213 139998094067520 util.py:204] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W1122 10:40:11.231344 139998094067520 util.py:204] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "W1122 10:40:11.231380 139998094067520 util.py:204] Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "W1122 10:40:11.231458 139998094067520 util.py:212] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=pupil/models/ssd_mobnet_coco_pupil --pipeline_config_path=pupil/models/ssd_mobnet_coco_pupil/pipeline.config --checkpoint_dir=pupil/models/ssd_mobnet_coco_pupil\n"
     ]
    }
   ],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lqTV2jGBpfDH",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 10:40:53.085133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 10:40:53.087466: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2021-11-22 10:40:53.087829: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W1122 10:40:53.090115 139972595029824 model_lib_v2.py:1082] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I1122 10:40:53.090230 139972595029824 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1122 10:40:53.090267 139972595029824 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I1122 10:40:53.090302 139972595029824 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W1122 10:40:53.090353 139972595029824 model_lib_v2.py:1103] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2021-11-22 10:40:53.092240: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['pupil/test.record']\n",
      "I1122 10:40:53.107653 139972595029824 dataset_builder.py:163] Reading unweighted datasets: ['pupil/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['pupil/test.record']\n",
      "I1122 10:40:53.107804 139972595029824 dataset_builder.py:80] Reading record datasets for input file: ['pupil/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1122 10:40:53.107855 139972595029824 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1122 10:40:53.107902 139972595029824 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W1122 10:40:53.109123 139972595029824 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1122 10:40:53.121727 139972595029824 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1122 10:40:56.005015 139972595029824 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1122 10:40:56.774530 139972595029824 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at pupil/models/ssd_mobnet_coco_pupil\n",
      "I1122 10:40:58.493417 139972595029824 checkpoint_utils.py:140] Waiting for new checkpoint at pupil/models/ssd_mobnet_coco_pupil\n",
      "INFO:tensorflow:Found new checkpoint at pupil/models/ssd_mobnet_coco_pupil/ckpt-3\n",
      "I1122 10:40:58.493942 139972595029824 checkpoint_utils.py:149] Found new checkpoint at pupil/models/ssd_mobnet_coco_pupil/ckpt-3\n",
      "/home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2021-11-22 10:40:58.554094: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1122 10:41:11.967990 139972595029824 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I1122 10:41:11.971130 139972595029824 model_lib_v2.py:958] Finished eval step 0\n",
      "WARNING:tensorflow:From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W1122 10:41:12.053814 139972595029824 deprecation.py:345] From /home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Performing evaluation on 18 images.\n",
      "I1122 10:41:12.958970 139972595029824 coco_evaluation.py:293] Performing evaluation on 18 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1122 10:41:12.959126 139972595029824 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I1122 10:41:12.960454 139972595029824 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.679\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.577\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.675\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.683\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.694\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.694\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.575\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "INFO:tensorflow:Eval metrics at step 2000\n",
      "I1122 10:41:13.052760 139972595029824 model_lib_v2.py:1007] Eval metrics at step 2000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.644284\n",
      "I1122 10:41:13.054189 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.644284\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "I1122 10:41:13.054514 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.678767\n",
      "I1122 10:41:13.054795 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.678767\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.577228\n",
      "I1122 10:41:13.055071 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.577228\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.674992\n",
      "I1122 10:41:13.055372 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.674992\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "I1122 10:41:13.055653 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.683333\n",
      "I1122 10:41:13.055926 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.683333\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.694444\n",
      "I1122 10:41:13.056199 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.694444\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.694444\n",
      "I1122 10:41:13.056462 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.694444\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.575000\n",
      "I1122 10:41:13.056733 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.575000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.733333\n",
      "I1122 10:41:13.057001 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.733333\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "I1122 10:41:13.057287 139972595029824 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): -1.000000\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.104381\n",
      "I1122 10:41:13.057524 139972595029824 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.104381\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.266274\n",
      "I1122 10:41:13.057760 139972595029824 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.266274\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.150155\n",
      "I1122 10:41:13.057994 139972595029824 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 0.150155\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.520810\n",
      "I1122 10:41:13.058227 139972595029824 model_lib_v2.py:1010] \t+ Loss/total_loss: 0.520810\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/absl/app.py\", line 303, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 90, in main\n",
      "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
      "  File \"/home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/object_detection/model_lib_v2.py\", line 1129, in eval_continuously\n",
      "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
      "  File \"/home/daniel/miniconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 216, in checkpoints_iterator\n",
      "    time.sleep(time_to_next_eval)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!{command} # Has to be manually stopped after displaying the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtUw73FHpfDK"
   },
   "source": [
    "# 6. Conversion to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XviMtewLpfDK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/export_tflite_graph_tf2.py  --pipeline_config_path=pupil/models/ssd_mobnet_coco_pupil/pipeline.config --trained_checkpoint_dir=pupil/models/ssd_mobnet_coco_pupil --output_directory=pupil/models/ssd_mobnet_coco_pupil/tfliteexport\n"
     ]
    }
   ],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')\n",
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-xWpHN8pfDL",
    "outputId": "7f6bacd8-d077-43b5-c131-5b081fba24a4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 10:42:10.912632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 10:42:10.915002: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-22 10:42:10.915360: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-22 10:42:10.919620: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fd430099910>, because it is not built.\n",
      "W1122 10:42:16.553418 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fd430099910>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3ec1aeed0>, because it is not built.\n",
      "W1122 10:42:16.673099 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3ec1aeed0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc112d50>, because it is not built.\n",
      "W1122 10:42:16.673208 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc112d50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc1633d0>, because it is not built.\n",
      "W1122 10:42:16.673258 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc1633d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3cc0ee4d0>, because it is not built.\n",
      "W1122 10:42:16.673300 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3cc0ee4d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc0ee1d0>, because it is not built.\n",
      "W1122 10:42:16.673340 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc0ee1d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc0eec90>, because it is not built.\n",
      "W1122 10:42:16.673380 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc0eec90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3cc0eec10>, because it is not built.\n",
      "W1122 10:42:16.673421 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3cc0eec10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc1baf50>, because it is not built.\n",
      "W1122 10:42:16.673460 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc1baf50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc1bad10>, because it is not built.\n",
      "W1122 10:42:16.673499 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc1bad10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3cc1ba610>, because it is not built.\n",
      "W1122 10:42:16.673537 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fd3cc1ba610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc1ba2d0>, because it is not built.\n",
      "W1122 10:42:16.673577 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc1ba2d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc112250>, because it is not built.\n",
      "W1122 10:42:16.673615 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc112250>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3ec1b6bd0>, because it is not built.\n",
      "W1122 10:42:16.673654 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3ec1b6bd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc03ff50>, because it is not built.\n",
      "W1122 10:42:16.673693 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc03ff50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc496b10>, because it is not built.\n",
      "W1122 10:42:16.673731 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc496b10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc03f850>, because it is not built.\n",
      "W1122 10:42:16.673769 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc03f850>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc0edf10>, because it is not built.\n",
      "W1122 10:42:16.673808 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc0edf10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc163310>, because it is not built.\n",
      "W1122 10:42:16.673846 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc163310>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc095e90>, because it is not built.\n",
      "W1122 10:42:16.673888 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc095e90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc095a90>, because it is not built.\n",
      "W1122 10:42:16.673932 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc095a90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3ec1b6c10>, because it is not built.\n",
      "W1122 10:42:16.673971 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3ec1b6c10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc0eeed0>, because it is not built.\n",
      "W1122 10:42:16.674010 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc0eeed0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc0a3f10>, because it is not built.\n",
      "W1122 10:42:16.674049 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc0a3f10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a8704d10>, because it is not built.\n",
      "W1122 10:42:16.674088 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a8704d10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a8704c10>, because it is not built.\n",
      "W1122 10:42:16.674126 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a8704c10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a8704d50>, because it is not built.\n",
      "W1122 10:42:16.674165 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a8704d50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a87045d0>, because it is not built.\n",
      "W1122 10:42:16.674203 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a87045d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc070bd0>, because it is not built.\n",
      "W1122 10:42:16.674241 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc070bd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc069f50>, because it is not built.\n",
      "W1122 10:42:16.674280 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc069f50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a86e7a10>, because it is not built.\n",
      "W1122 10:42:16.674321 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a86e7a10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86e7110>, because it is not built.\n",
      "W1122 10:42:16.674360 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86e7110>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a86e7dd0>, because it is not built.\n",
      "W1122 10:42:16.674398 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a86e7dd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86e7d90>, because it is not built.\n",
      "W1122 10:42:16.674436 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86e7d90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc06f610>, because it is not built.\n",
      "W1122 10:42:16.674476 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc06f610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc113350>, because it is not built.\n",
      "W1122 10:42:16.674517 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc113350>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a870b250>, because it is not built.\n",
      "W1122 10:42:16.674559 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a870b250>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3ec1b6c50>, because it is not built.\n",
      "W1122 10:42:16.674599 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3ec1b6c50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a86f8d10>, because it is not built.\n",
      "W1122 10:42:16.674638 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a86f8d10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86f8f90>, because it is not built.\n",
      "W1122 10:42:16.674676 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86f8f90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc2e1fd0>, because it is not built.\n",
      "W1122 10:42:16.674715 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc2e1fd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86f8550>, because it is not built.\n",
      "W1122 10:42:16.674753 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3a86f8550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc43d3d0>, because it is not built.\n",
      "W1122 10:42:16.674794 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3cc43d3d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc1631d0>, because it is not built.\n",
      "W1122 10:42:16.674832 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fd3cc1631d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a869e0d0>, because it is not built.\n",
      "W1122 10:42:16.674871 140553496201024 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.Lambda object at 0x7fd3a869e0d0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 10:42:22.122133: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W1122 10:42:31.964796 140553496201024 save.py:254] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: pupil/models/ssd_mobnet_coco_pupil/tfliteexport/saved_model/assets\n",
      "I1122 10:42:34.829211 140553496201024 builder_impl.py:781] Assets written to: pupil/models/ssd_mobnet_coco_pupil/tfliteexport/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iJfYMbN6pfDL"
   },
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', objectChooser.value + '.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite_convert --saved_model_dir=pupil/models/ssd_mobnet_coco_pupil/tfliteexport/saved_model --output_file=pupil/models/ssd_mobnet_coco_pupil/tfliteexport/saved_model/pupil.tflite --input_shapes=1,320,320,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops\n"
     ]
    }
   ],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,320,320,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nbd7gqHMpfDL",
    "outputId": "7c8fe6d5-2415-4641-8548-39d425c202f7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 10:42:42.757947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-22 10:42:42.760448: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-22 10:42:42.760798: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-22 10:42:43.197188: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-22 10:42:50.813687: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2021-11-22 10:42:50.813706: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2021-11-22 10:42:50.813712: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored change_concat_input_ranges.\n",
      "2021-11-22 10:42:50.814420: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: pupil/models/ssd_mobnet_coco_pupil/tfliteexport/saved_model\n",
      "2021-11-22 10:42:50.891601: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2021-11-22 10:42:50.891642: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: pupil/models/ssd_mobnet_coco_pupil/tfliteexport/saved_model\n",
      "2021-11-22 10:42:51.135192: I tensorflow/cc/saved_model/loader.cc:211] Restoring SavedModel bundle.\n",
      "2021-11-22 10:42:51.636361: I tensorflow/cc/saved_model/loader.cc:195] Running initialization op on SavedModel bundle at path: pupil/models/ssd_mobnet_coco_pupil/tfliteexport/saved_model\n",
      "2021-11-22 10:42:51.851167: I tensorflow/cc/saved_model/loader.cc:283] SavedModel load for tags { serve }; Status: success: OK. Took 1036747 microseconds.\n",
      "2021-11-22 10:42:52.605722: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2021-11-22 10:42:53.263021: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1899] Estimated count of arithmetic ops: 1.698 G  ops, equivalently 0.849 G  MACs\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3. Training and Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
